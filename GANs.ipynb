{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0,1)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(.5,.5,.5), std=(.5,.5,.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# datasets, dataloader\n",
    "dsets = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_loader = torch.utils.data.DataLoader(dataset=dsets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(nn.Linear(784, 256), \n",
    "                  nn.LeakyReLU(.2), \n",
    "                  nn.Linear(256, 256), \n",
    "                  nn.LeakyReLU(.2), \n",
    "                  nn.Linear(256, 1), \n",
    "                  nn.Sigmoid())\n",
    "\n",
    "# Generator\n",
    "G = nn.Sequential(nn.Linear(64, 256), \n",
    "                  nn.LeakyReLU(.2), \n",
    "                  nn.Linear(256, 256), \n",
    "                  nn.LeakyReLU(.2), \n",
    "                  nn.Linear(256, 784), \n",
    "                  nn.Tanh())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    D.cuda()\n",
    "    G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary loss entropy and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('data/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/200, Iterations:  300, d_loss: 0.4402, g_loss: 2.4957, D(x): 0.93, D(G(z)): 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2/200, Iterations:  300, d_loss: 0.4921, g_loss: 2.7280, D(x): 0.80, D(G(z)): 0.13\n",
      "Epoch:   3/200, Iterations:  300, d_loss: 0.3390, g_loss: 3.3649, D(x): 0.85, D(G(z)): 0.10\n",
      "Epoch:   4/200, Iterations:  300, d_loss: 1.5264, g_loss: 1.9026, D(x): 0.58, D(G(z)): 0.33\n",
      "Epoch:   5/200, Iterations:  300, d_loss: 0.8980, g_loss: 1.6728, D(x): 0.71, D(G(z)): 0.29\n",
      "Epoch:   6/200, Iterations:  300, d_loss: 2.0298, g_loss: 1.6152, D(x): 0.56, D(G(z)): 0.40\n",
      "Epoch:   7/200, Iterations:  300, d_loss: 0.5688, g_loss: 2.0982, D(x): 0.83, D(G(z)): 0.24\n",
      "Epoch:   8/200, Iterations:  300, d_loss: 0.6221, g_loss: 3.5193, D(x): 0.81, D(G(z)): 0.22\n",
      "Epoch:   9/200, Iterations:  300, d_loss: 0.9517, g_loss: 2.0178, D(x): 0.75, D(G(z)): 0.34\n",
      "Epoch:  10/200, Iterations:  300, d_loss: 0.8668, g_loss: 1.8030, D(x): 0.83, D(G(z)): 0.37\n",
      "Epoch:  11/200, Iterations:  300, d_loss: 0.7450, g_loss: 2.4188, D(x): 0.78, D(G(z)): 0.29\n",
      "Epoch:  12/200, Iterations:  300, d_loss: 0.5217, g_loss: 2.0539, D(x): 0.85, D(G(z)): 0.26\n",
      "Epoch:  13/200, Iterations:  300, d_loss: 1.0680, g_loss: 1.9600, D(x): 0.69, D(G(z)): 0.34\n",
      "Epoch:  14/200, Iterations:  300, d_loss: 0.7322, g_loss: 1.7035, D(x): 0.77, D(G(z)): 0.28\n",
      "Epoch:  15/200, Iterations:  300, d_loss: 1.1084, g_loss: 1.4486, D(x): 0.70, D(G(z)): 0.40\n",
      "Epoch:  16/200, Iterations:  300, d_loss: 0.7683, g_loss: 2.2070, D(x): 0.79, D(G(z)): 0.32\n",
      "Epoch:  17/200, Iterations:  300, d_loss: 0.9469, g_loss: 1.9917, D(x): 0.69, D(G(z)): 0.21\n",
      "Epoch:  18/200, Iterations:  300, d_loss: 1.6574, g_loss: 1.6571, D(x): 0.55, D(G(z)): 0.42\n",
      "Epoch:  19/200, Iterations:  300, d_loss: 1.0250, g_loss: 2.2594, D(x): 0.69, D(G(z)): 0.36\n",
      "Epoch:  20/200, Iterations:  300, d_loss: 0.9558, g_loss: 2.0434, D(x): 0.70, D(G(z)): 0.26\n",
      "Epoch:  21/200, Iterations:  300, d_loss: 0.7407, g_loss: 2.1448, D(x): 0.69, D(G(z)): 0.19\n",
      "Epoch:  22/200, Iterations:  300, d_loss: 1.0523, g_loss: 3.0342, D(x): 0.65, D(G(z)): 0.22\n",
      "Epoch:  23/200, Iterations:  300, d_loss: 0.7308, g_loss: 2.4033, D(x): 0.76, D(G(z)): 0.27\n",
      "Epoch:  24/200, Iterations:  300, d_loss: 0.6294, g_loss: 2.0090, D(x): 0.81, D(G(z)): 0.27\n",
      "Epoch:  25/200, Iterations:  300, d_loss: 0.7609, g_loss: 2.2329, D(x): 0.71, D(G(z)): 0.18\n",
      "Epoch:  26/200, Iterations:  300, d_loss: 0.8611, g_loss: 2.2168, D(x): 0.76, D(G(z)): 0.30\n",
      "Epoch:  27/200, Iterations:  300, d_loss: 0.9788, g_loss: 2.6537, D(x): 0.65, D(G(z)): 0.20\n",
      "Epoch:  28/200, Iterations:  300, d_loss: 1.1839, g_loss: 2.0322, D(x): 0.68, D(G(z)): 0.33\n",
      "Epoch:  29/200, Iterations:  300, d_loss: 0.9727, g_loss: 1.6379, D(x): 0.64, D(G(z)): 0.23\n",
      "Epoch:  30/200, Iterations:  300, d_loss: 1.0892, g_loss: 2.0809, D(x): 0.67, D(G(z)): 0.37\n",
      "Epoch:  31/200, Iterations:  300, d_loss: 1.3050, g_loss: 1.6703, D(x): 0.66, D(G(z)): 0.45\n",
      "Epoch:  32/200, Iterations:  300, d_loss: 0.8951, g_loss: 1.6386, D(x): 0.67, D(G(z)): 0.27\n",
      "Epoch:  33/200, Iterations:  300, d_loss: 0.7424, g_loss: 2.2048, D(x): 0.79, D(G(z)): 0.29\n",
      "Epoch:  34/200, Iterations:  300, d_loss: 1.0285, g_loss: 1.5240, D(x): 0.70, D(G(z)): 0.34\n",
      "Epoch:  35/200, Iterations:  300, d_loss: 0.7844, g_loss: 1.8872, D(x): 0.76, D(G(z)): 0.28\n",
      "Epoch:  36/200, Iterations:  300, d_loss: 0.8157, g_loss: 1.4503, D(x): 0.74, D(G(z)): 0.31\n",
      "Epoch:  37/200, Iterations:  300, d_loss: 0.8504, g_loss: 1.6971, D(x): 0.74, D(G(z)): 0.28\n",
      "Epoch:  38/200, Iterations:  300, d_loss: 0.9190, g_loss: 1.8025, D(x): 0.70, D(G(z)): 0.28\n",
      "Epoch:  39/200, Iterations:  300, d_loss: 0.8213, g_loss: 2.0670, D(x): 0.71, D(G(z)): 0.22\n",
      "Epoch:  40/200, Iterations:  300, d_loss: 0.9377, g_loss: 2.0640, D(x): 0.64, D(G(z)): 0.21\n",
      "Epoch:  41/200, Iterations:  300, d_loss: 0.7483, g_loss: 1.4309, D(x): 0.80, D(G(z)): 0.31\n",
      "Epoch:  42/200, Iterations:  300, d_loss: 1.1489, g_loss: 1.3063, D(x): 0.58, D(G(z)): 0.29\n",
      "Epoch:  43/200, Iterations:  300, d_loss: 1.2036, g_loss: 1.5107, D(x): 0.66, D(G(z)): 0.39\n",
      "Epoch:  44/200, Iterations:  300, d_loss: 1.0913, g_loss: 1.8873, D(x): 0.65, D(G(z)): 0.32\n",
      "Epoch:  45/200, Iterations:  300, d_loss: 0.7888, g_loss: 1.8553, D(x): 0.70, D(G(z)): 0.27\n",
      "Epoch:  46/200, Iterations:  300, d_loss: 0.8141, g_loss: 1.8010, D(x): 0.65, D(G(z)): 0.22\n",
      "Epoch:  47/200, Iterations:  300, d_loss: 0.9726, g_loss: 1.4966, D(x): 0.63, D(G(z)): 0.27\n",
      "Epoch:  48/200, Iterations:  300, d_loss: 0.7734, g_loss: 2.1129, D(x): 0.76, D(G(z)): 0.27\n",
      "Epoch:  49/200, Iterations:  300, d_loss: 0.9028, g_loss: 1.6910, D(x): 0.73, D(G(z)): 0.30\n",
      "Epoch:  50/200, Iterations:  300, d_loss: 0.8553, g_loss: 1.5761, D(x): 0.69, D(G(z)): 0.27\n",
      "Epoch:  51/200, Iterations:  300, d_loss: 0.8143, g_loss: 1.9932, D(x): 0.71, D(G(z)): 0.26\n",
      "Epoch:  52/200, Iterations:  300, d_loss: 0.8749, g_loss: 1.8090, D(x): 0.66, D(G(z)): 0.25\n",
      "Epoch:  53/200, Iterations:  300, d_loss: 1.1590, g_loss: 1.6730, D(x): 0.72, D(G(z)): 0.42\n",
      "Epoch:  54/200, Iterations:  300, d_loss: 0.8010, g_loss: 1.7985, D(x): 0.76, D(G(z)): 0.30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8f4101cf57e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# build mini-batch datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2414\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \"\"\"\n\u001b[0;32m-> 2416\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "for epoch in range(200):\n",
    "    for i, (images, _) in enumerate(dsets_loader):\n",
    "        # build mini-batch datasets\n",
    "        batch_size = images.size(0)\n",
    "        images = to_var(images.view(batch_size, -1))\n",
    "        \n",
    "        # create the labels which are later used for input for loss computation\n",
    "        real_labels = to_var(torch.ones(batch_size))\n",
    "        fake_labels = to_var(torch.zeros(batch_size))\n",
    "        \n",
    "        #========== Train the discriminator ============#\n",
    "        # compute BCELoss using real images where BCELoss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # second term of the loss is always 0 since real_labels == 1 : - y * log(D(x))\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # compute BCELoss using fake images\n",
    "        # first term of the loss is always 0 since fake_labels == 0 : - (1-y) * log(1 - D(x))\n",
    "        z = to_var(torch.randn(batch_size, 64))\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # backprop, optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        #========== Train the generator ============#\n",
    "        # compute loss using fake images\n",
    "        z = to_var(torch.randn(batch_size, 64))\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # train G to maximize log(D(G(z))) instead of minimizing log(1 - D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # backprop, optimizer\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 300 == 0:\n",
    "            print(\"Epoch: {0:3d}/200,\".format(epoch+1), \n",
    "                  \"Iterations: {0:4d},\".format(i+1), \n",
    "                  \"d_loss: {:.4f},\".format(d_loss.data[0]), \n",
    "                  \"g_loss: {:.4f},\".format(g_loss.data[0]), \n",
    "                  \"D(x): {:.2f},\".format(real_score.data.mean()), \n",
    "                  \"D(G(z)): {:.2f}\".format(fake_score.data.mean()))\n",
    "    \n",
    "    # save real images\n",
    "    if (epoch + 1) == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images.data), 'data/images/real_images.png')\n",
    "        \n",
    "    # save sampled images\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images.data), 'data/images/fake_images_%d.png' % (epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state.dict(), 'generator.pkl')\n",
    "torch.save(D.state.dict(), 'discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
